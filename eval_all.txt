week1
Bert ms256:
	coronation_street
		eval_accuracy = 0.8253817
		eval_loss = 1.374492
		global_step = 18750
		loss = 1.0880518

	ice_hockey
		eval_accuracy = 0.72961956
		eval_loss = 2.8742874
		global_step = 18750
		loss = 2.4326644

	muppets
		eval_accuracy = 0.79679805
		eval_loss = 1.6510948
		global_step = 18750
		loss = 1.6400665

	elder_scrolls
		eval_accuracy = 0.6969697
		eval_loss = 2.4781182
		global_step = 18750
		loss = 2.4632294

ALBERT_base ms256:
	coronation_street
		eval_accuracy = 0.76854396
		eval_loss = 2.1526203
		global_step = 18750
		loss = 1.716161
	ice_hockey
		eval_accuracy = 0.5748208
		eval_loss = 4.3792486
		global_step = 18750
		loss = 4.503334
	muppets
		eval_accuracy = 0.7277668
		eval_loss = 2.475906
		global_step = 18750
		loss = 2.0622356
	elder_scrolls
		eval_accuracy = 0.619382
		eval_loss = 3.2440367
		global_step = 18750
		loss = 3.2893763

ALBERT_base ms512:
	coronation_street
		eval_accuracy = 0.77953297
		eval_loss = 1.8312002
		global_step = 18750
		loss = 2.1265833
	ice_hockey
		eval_accuracy = 0.61290324
		eval_loss = 3.6361141
		global_step = 18750
		loss = 3.4497175
	muppets
		eval_accuracy = 0.7346838
		eval_loss = 2.1614032
		global_step = 18750
		loss = 1.8970973
	elder_scrolls
		eval_accuracy = 0.6502809
		eval_loss = 2.8559
		global_step = 18750
		loss = 2.8770096

ALBERT_large ms256:
	coronation_street
		24750:
			eval_accuracy = 0.8063187
			eval_loss = 2.2253451
			global_step = 24750
			loss = 2.4081266
		18750:
			eval_accuracy = 0.82417583
			eval_loss = 1.924539
			global_step = 18750
			loss = 1.950443
		15000:
			eval_accuracy = 0.81593406
			eval_loss = 1.7239933
			global_step = 15000
			loss = 1.6507592
		12000:
			eval_accuracy = 0.82486266
			eval_loss = 1.3745958
			global_step = 12000
			loss = 1.3485233
		9000:
			eval_accuracy = 0.80288464
			eval_loss = 1.562472
			global_step = 9000
			loss = 1.5036693
	ice_hockey
		24650:
			eval_accuracy = 0.5994624
			eval_loss = 4.762148
			global_step = 24750
			loss = 4.213555
		18750:
			eval_accuracy = 0.608871
			eval_loss = 4.2449007
			global_step = 18750
			loss = 3.7827244
		15000:
			eval_accuracy = 0.6066308
			eval_loss = 4.1799054
			global_step = 15000
			loss = 3.7433698
		12000:
			eval_accuracy = 0.6066308
			eval_loss = 3.148604
			global_step = 12000
			loss = 2.7891622
		9000:
			eval_accuracy = 0.60215056
			eval_loss = 3.3510575
			global_step = 9000
			loss = 3.4661303
	muppets
		24750:
			eval_accuracy = 0.7277668
			eval_loss = 2.9996374
			global_step = 24750
			loss = 2.6986156
		18750:
			eval_accuracy = 0.73567194
			eval_loss = 2.656763
			global_step = 18750
			loss = 2.3488584
		15000:
			eval_accuracy = 0.73221344
			eval_loss = 2.3595035
			global_step = 15000
			loss = 2.0421848
		12000:
			eval_accuracy = 0.7302371
			eval_loss = 2.028221
			global_step = 12000
			loss = 1.8596017
		9000:
			eval_accuracy = 0.7302371
			eval_loss = 2.1339931
			global_step = 9000
			loss = 1.7624897
	elder_scrolls
		24750:
			eval_accuracy = 0.62312734
			eval_loss = 3.951129
			global_step = 24750
			loss = 4.4534864

		18750:
			eval_accuracy = 0.63459736
			eval_loss = 3.4734569
			global_step = 18750
			loss = 3.7600627
		15000:
			eval_accuracy = 0.6425562
			eval_loss = 3.0041566
			global_step = 15000
			loss = 3.172907
		12000:
			eval_accuracy = 0.6331929
			eval_loss = 2.6286383
			global_step = 12000
			loss = 2.8228831
		9000:
			eval_accuracy = 0.6369382
			eval_loss = 2.4285567
			global_step = 9000
			loss = 2.7317069

ALBERT_large ms256_amsoftmax:
	coronation_street
		18750:
			eval_accuracy = 0.78983516
			eval_loss = 2.9850314
			global_step = 18750
			loss = 3.0308762
		15000:
			eval_accuracy = 0.7815934
			eval_loss = 2.8678038
			global_step = 15000
			loss = 2.9915664
	ice_hockey
		18750:
			eval_accuracy = 0.61738354
			eval_loss = 6.067696
			global_step = 18750
			loss = 5.3465743
		15000:
			eval_accuracy = 0.60215056
			eval_loss = 5.5003133
			global_step = 15000
			loss = 4.779437
	muppets
		18750:
			eval_accuracy = 0.74110675
			eval_loss = 3.6981618
			global_step = 18750
			loss = 2.9942508
		15000:
			eval_accuracy = 0.7351779
			eval_loss = 3.5568564
			global_step = 15000
			loss = 2.9495783
	elder_scrolls
		18750:
			eval_accuracy = 0.6355337
			eval_loss = 4.784646
			global_step = 18750
			loss = 5.299707
		15000:
			eval_accuracy = 0.630618
			eval_loss = 4.1567936
			global_step = 15000
			loss = 4.45726
------------------------------------------------------------------------------------------
Week2
Bert ms512_48:
很有可能发生的原因：384 128有有很多padding，255 255就会好很多。而在albert384 128也好的原因是sentence piece对比wordpiece相同情况下少很多padding。

	train384_128 test384_128:  				0.73389249086
		coronation_street:
			eval_accuracy = 0.7912088
			eval_loss = 1.7343221
			global_step = 18750
			loss = 1.7325134
		ice_hockey:
			eval_accuracy = 0.71146953
			eval_loss = 3.0319192
			global_step = 18750
			loss = 2.8942568
		muppets:
			eval_accuracy = 0.77272725
			eval_loss = 1.8869402
			global_step = 18750
			loss = 1.7082815
		elder_scrolls:
			eval_accuracy = 0.7076311
			eval_loss = 2.5060909
			global_step = 18750
			loss = 2.7518344

	train384_128 test255_255:				0.73946967905
		coronation_street:
			eval_accuracy = 0.82623625
			eval_loss = 1.5390313
			global_step = 18750
			loss = 1.530455		
		ice_hockey:
			eval_accuracy = 0.70654124
			eval_loss = 3.1011977
			global_step = 18750
			loss = 3.3235602
		muppets:
			eval_accuracy = 0.78310275
			eval_loss = 1.823563
			global_step = 18750
			loss = 1.4829438
		elder_scrolls:
			eval_accuracy = 0.70646065
			eval_loss = 2.4674952
			global_step = 18750
			loss = 2.5930345

	train384_128 test128_384:				0.73196848287
		coronation_street:
			eval_accuracy = 0.8385989
			eval_loss = 1.2141138
			global_step = 18750
			loss = 1.3624961	
		ice_hockey:
			eval_accuracy = 0.6886201
			eval_loss = 3.4567566
			global_step = 18750
			loss = 3.353269
		muppets:
			eval_accuracy = 0.78507906
			eval_loss = 1.771818
			global_step = 18750
			loss = 1.3788221
		elder_scrolls:
			eval_accuracy = 0.6928839
			eval_loss = 2.6585417
			global_step = 18750
			loss = 2.7140794


	train255_255 test255_255:				0.74489890202
		coronation_street:
			eval_accuracy = 0.80906594
			eval_loss = 1.4221852
			global_step = 18750
			loss = 1.1246779	
		ice_hockey:
			eval_accuracy = 0.71505374
			eval_loss = 2.7103276
			global_step = 18750
			loss = 2.882507
		muppets:
			eval_accuracy = 0.7751976
			eval_loss = 1.9692776
			global_step = 18750
			loss = 1.5692787
		elder_scrolls:
			eval_accuracy = 0.7237828
			eval_loss = 2.4390965
			global_step = 18750
			loss = 2.6193678

	train255_255 test384_128:				0.71717016297
		coronation_street:
			eval_accuracy = 0.7630494
			eval_loss = 1.9843526
			global_step = 18750
			loss = 1.7517833
		ice_hockey:
			eval_accuracy = 0.6863799
			eval_loss = 2.9277663
			global_step = 18750
			loss = 3.0596657
		muppets:
			eval_accuracy = 0.7559289
			eval_loss = 2.140228
			global_step = 18750
			loss = 1.7565297
		elder_scrolls:
			eval_accuracy = 0.6980337
			eval_loss = 2.6708722
			global_step = 18750
			loss = 3.084367

	train255_255 test128_384:				0.72702510605
		coronation_street:
			eval_accuracy = 0.80494505
			eval_loss = 1.4851861
			global_step = 18750
			loss = 1.1629953
		ice_hockey:
			eval_accuracy = 0.6778674
			eval_loss = 3.0377393
			global_step = 18750
			loss = 3.0686662
		muppets:
			eval_accuracy = 0.7618577
			eval_loss = 1.9639674
			global_step = 18750
			loss = 1.4733629
		elder_scrolls:
			eval_accuracy = 0.7078652
			eval_loss = 2.5683317
			global_step = 18750
			loss = 2.810178

